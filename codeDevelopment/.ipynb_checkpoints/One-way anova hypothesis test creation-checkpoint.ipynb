{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime as dt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import dataStatsAnalysis_old as dsa\n",
    "import dataStatsPlotting as dsp\n",
    "\n",
    "dsp.SetParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnimplementedMethodException(Exception):\n",
    "    \"\"\"Exception if someone calls a method that should be overridden.\"\"\"\n",
    "\n",
    "\n",
    "class HypothesisTest():\n",
    "    \"\"\"Hypothesis test superclass. \n",
    "\n",
    "    This class cannot be used as is. \n",
    "    It is to be used to construct hypothesis tests \n",
    "    for various different test statistics. \n",
    "    See the existing child classes below for examples.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, tail='right', iters=1000):\n",
    "        self.data = data\n",
    "        self.tail = tail\n",
    "        self.iters = iters\n",
    "        self.PrepareData(data)\n",
    "        self.TestStat()\n",
    "        self.sampling_dist, self.rv = self.ComputeRv() # pylint: disable=assignment-from-no-return\n",
    "\n",
    "    # Provide the functionality to convert the data into the format needed \n",
    "    # for use in ComputeRv and Power functions. \n",
    "    # Ex. Convert to array, split data into component groups, etc. \n",
    "    # The self data variables must be created in the function, not returned. \n",
    "    # See child classes for examples\n",
    "    def PrepareData(self, data):\n",
    "        UnimplementedMethodException()\n",
    "        \n",
    "    # This function only needs to be written in the case of a null hypothesis based test. \n",
    "    # The self.test_stat needs to be created in the function, not returned. \n",
    "    # In the case of an alternative hypothesis based test \n",
    "    # test_stat will be provided via a class parameter. \n",
    "    # See child classes for examples\n",
    "    def TestStat(self):\n",
    "        pass\n",
    "    \n",
    "    # Provide the functionality that computes the sampling distribution and rv for the data.\n",
    "    # Both the sampling distribution and the rv need to be returned by the function \n",
    "    # See child classes for examples\n",
    "    def ComputeRv(self):\n",
    "        UnimplementedMethodException()\n",
    "        \n",
    "    # Provide the functionality that computes the power by running multiple iterations of the hypothesis test.\n",
    "    # The code in the for loop must first create new data for the run, \n",
    "    # which simulates taking another sample from the population, and then run the hypothesis test.\n",
    "    # See child classes for examples\n",
    "    def Power(self):\n",
    "        UnimplementedMethodException()\n",
    "    \n",
    "    def PValue(self):\n",
    "        \"\"\"Computes the p-value for the hypothesis test.\n",
    "\n",
    "        returns: float p-value\n",
    "        \"\"\"\n",
    "        if self.tail == 'left':\n",
    "            pvalue = self.rv.cdf(self.test_stat) # pylint: disable=no-member\n",
    "        elif self.tail == 'right':\n",
    "            pvalue = 1 - self.rv.cdf(self.test_stat) # pylint: disable=no-member\n",
    "        else:\n",
    "            raise Exception('The value of \\'tail\\' can only be either \\'left\\' or \\'right\\'')\n",
    "\n",
    "        return pvalue\n",
    "\n",
    "    def MinMaxTestStat(self):\n",
    "        \"\"\"Returns the smallest and largest test statistics in the sampling distribution.\n",
    "        \"\"\"\n",
    "        return min(self.sampling_dist), max(self.sampling_dist)\n",
    "\n",
    "    def PlotCdf(self):\n",
    "        \"\"\"Draws a Cdf with a vertical line at the test stat.\n",
    "        \"\"\"      \n",
    "        plt.plot(self.rv.xk, self.rv.cdf(self.rv.xk), color='C0', lw=2) # pylint: disable=no-member\n",
    "        \n",
    "        plt.axvline(self.test_stat, color='C1', lw=1.3) # pylint: disable=no-member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTOnewayAnova(HypothesisTest):\n",
    "    \"\"\"A chi square hypothesis test. \n",
    "    Uses resampling of the expected sequence to simulate the null hypothesis \n",
    "    and build the null hypothesis chi square statistic sampling distribution. \n",
    "    Accepts data in the form of a list or tuple of two sequences (observed, expected).\n",
    "    The passed sequences must be the same length, be integer counts of a categorical variable \n",
    "    and the sum of the sequence values must be the same. \n",
    "    If the sum of the sequence values is different, first normalize the expected values \n",
    "    and then create a new expected values sequence by multiplying by the total number of observed values. \n",
    "    adjust_expected = expected/sum(expected)*sum(observed)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data (array-like):\n",
    "        A list or tuple of two sequences (observed, expected)\n",
    "    tail (str):\n",
    "        The tail of the distribution to be used in the PValue function\n",
    "        Accepts only 'right' or 'left'\n",
    "        Defaults to 'right'\n",
    "    iters (int):\n",
    "        The number of iterations to run in the ComputeRv function \n",
    "        Defaults to 1000\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    data:\n",
    "        The original data\n",
    "    test_stat:\n",
    "        The test statistic used in the hypothesis test\n",
    "    sampling_dist:\n",
    "        The sampling distribution generated by resampling\n",
    "    rv:\n",
    "        A scipy.stats discrete_rv object (random variable) \n",
    "        that represents the sampling distribution\n",
    "        This object provides numerous useful attributes and methods\n",
    "        See the discrete_rv documentation for details\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    PValue():\n",
    "        Computes the p-value for the hypothesis test\n",
    "    Power(alpha=0.05, num_runs=1000):\n",
    "        Computes the power of the hypothesis test\n",
    "        alpha: the significance level for the hypothesis test, default=0.05\n",
    "        num_runs: the number of hypothesis tests to run, default=1000\n",
    "    MinMaxTestStat():\n",
    "        Returns the smallest and largest test statistics in the sampling distribution\n",
    "    PlotCdf():\n",
    "        Draws a Cdf of the distribution with a vertical line at the test stat\n",
    "    \"\"\"\n",
    "    def PrepareData(self, data):\n",
    "        self.pooled_data = np.hstack(data)\n",
    "        \n",
    "    def TestStat(self):\n",
    "        self.test_stat, _ = stats.f_oneway(*data)\n",
    "        \n",
    "    def ComputeRv(self):\n",
    "        # Calculate the variables needed for resampling        \n",
    "        \n",
    "        \n",
    "        # Build the sampling distribution\n",
    "        f_stats = []\n",
    "        \n",
    "        for _ in range(self.iters):\n",
    "            pooled_data_perm = np.random.permutation(self.pooled_data)\n",
    "            data_perm_list = []\n",
    "            \n",
    "            for x in self.data:\n",
    "                x_perm = pooled_data_perm[:len(x)]\n",
    "                data_perm_list.append(x_perm)\n",
    "    \n",
    "                pooled_data_perm = pooled_data_perm[len(x):]\n",
    "                \n",
    "                f_stat, _ = stats.f_oneway(*data_perm_list)\n",
    "            \n",
    "            f_stats.append(f_stat)\n",
    "            \n",
    "        return np.array(f_stats), dsa.DiscreteRv(f_stats)\n",
    "    \n",
    "#     def Power(self, alpha=0.05, num_runs=1000):\n",
    "#         \"\"\"Computes the power of the hypothesis test. \n",
    "\n",
    "#         Args\n",
    "#         ----\n",
    "#         alpha (float):\n",
    "#             The significance level for the hypothesis test.\n",
    "#             Must be between 0 and 1. Defaults to 0.05\n",
    "#         num_runs (int):\n",
    "#             The number of times to run the hypothesis test to compute power.\n",
    "#             Defaults to 1000.\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         power:\n",
    "#             Computed as the percentage of significant pvalues in num_runs of the test.\n",
    "#             Returned value is between 0 and 1.\n",
    "#         \"\"\"    \n",
    "#         pvalue_count = 0\n",
    "        \n",
    "#         for _ in range(num_runs):\n",
    "#             # Create a new run_observed by resampling the observed sequence \n",
    "#             # Then create the new run_data using run_observed and the original expected sequence\n",
    "#             n = sum(self.observed)\n",
    "#             values_obs = list(range(len(self.observed)))\n",
    "#             p_obs = self.observed/sum(self.observed)\n",
    "        \n",
    "#             hist = Counter({x:0 for x in values_obs})\n",
    "#             hist.update(np.random.choice(values_obs, size=n, replace=True, p=p_obs))\n",
    "#             sorted_hist = sorted(hist.items())\n",
    "#             run_observed = np.array([x[1] for x in sorted_hist])\n",
    "#             run_data = run_observed, self.expected\n",
    "\n",
    "#             # Run the hypothesis test with run_data\n",
    "#             test = HTChiSquare(run_data, tail=self.tail, iters=100)\n",
    "#             pvalue = test.PValue()\n",
    "            \n",
    "#             if pvalue < alpha:\n",
    "#                 pvalue_count += 1\n",
    "            \n",
    "#         return pvalue_count / num_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to use: comes from the scipy.stats.f_oneway example\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html\n",
    "\n",
    "tillamook = [0.0571, 0.0813, 0.0831, 0.0976, 0.0817, 0.0859, 0.0735,\n",
    "             0.0659, 0.0923, 0.0836]\n",
    "newport = [0.0873, 0.0662, 0.0672, 0.0819, 0.0749, 0.0649, 0.0835,\n",
    "           0.0725]\n",
    "petersburg = [0.0974, 0.1352, 0.0817, 0.1016, 0.0968, 0.1064, 0.105]\n",
    "magadan = [0.1033, 0.0915, 0.0781, 0.0685, 0.0677, 0.0697, 0.0764,\n",
    "           0.0689]\n",
    "tvarminne = [0.0703, 0.1026, 0.0956, 0.0973, 0.1039, 0.1045]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=7.121019471642447, pvalue=0.0002812242314534544)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f_oneway(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0.0649, 0.0781, 0.0835, 0.0749, 0.1033, 0.1045, 0.0817, 0.0764,\n",
       "         0.0689, 0.1352]),\n",
       "  array([0.0735, 0.0974, 0.0873, 0.0976, 0.105 , 0.0725, 0.0677, 0.0659]),\n",
       "  array([0.0813, 0.0836, 0.0697, 0.0685, 0.0831, 0.0923, 0.0819]),\n",
       "  array([0.0703, 0.0968, 0.1064, 0.0817, 0.1026, 0.0672, 0.0571, 0.0956]),\n",
       "  array([0.0915, 0.0662, 0.1039, 0.0973, 0.0859, 0.1016])],\n",
       " F_onewayResult(statistic=0.4118576440954995, pvalue=0.7988356024907164))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try permutation , petersburg_perm, magadan_perm, tvarminne_perm\n",
    "\n",
    "data = [tillamook, newport, petersburg, magadan, tvarminne]\n",
    "pooled_data = np.hstack(data)\n",
    "pooled_data_perm = np.random.permutation(pooled_data)\n",
    "\n",
    "data_perm_list = []\n",
    "for x in data:\n",
    "    x_perm = pooled_data_perm[:len(x)]\n",
    "    data_perm_list.append(x_perm)\n",
    "    \n",
    "    pooled_data_perm = pooled_data_perm[len(x):]\n",
    "\n",
    "data_perm_list, stats.f_oneway(*data_perm_list)\n",
    "# pooled_data_perm = np.random.permutation(pooled_data)\n",
    "# tillamook_perm = pooled_data_perm[:len(tillamook)]\n",
    "# newport_perm = pooled_data_perm[len(tillamook):len(tillamook)+len(newport)]\n",
    "# petersburg\n",
    "\n",
    "# tillamook_perm, newport_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0571,\n",
       "  0.0813,\n",
       "  0.0831,\n",
       "  0.0976,\n",
       "  0.0817,\n",
       "  0.0859,\n",
       "  0.0735,\n",
       "  0.0659,\n",
       "  0.0923,\n",
       "  0.0836],\n",
       " [0.0873, 0.0662, 0.0672, 0.0819, 0.0749, 0.0649, 0.0835, 0.0725],\n",
       " [0.0974, 0.1352, 0.0817, 0.1016, 0.0968, 0.1064, 0.105],\n",
       " [0.1033, 0.0915, 0.0781, 0.0685, 0.0677, 0.0697, 0.0764, 0.0689],\n",
       " [0.0703, 0.1026, 0.0956, 0.0973, 0.1039, 0.1045]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might be working now, but hard to tell because the pvalues are so low\n",
    "# Should try changing the numbers a bit to get a higher pvalue\n",
    "# Still need to create the Power part\n",
    "htanova = HTOnewayAnova(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009999999999992237"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htanova.PValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.016241385059404173, 8.013588563313762)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htanova.MinMaxTestStat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.121019471642447"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htanova.test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda24f47ca32af24772af08039f921d0b59"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
